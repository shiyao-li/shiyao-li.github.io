<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shiyao Li</title>
  
  <meta name="author" content="Shiyao Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="assets/fly.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- Bio -->
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shiyao Li</name>
              </p>
              <p>
                I am currently a PhD student at <a href="https://imagine-lab.enpc.fr/">IMAGINE (ENPC)</a> and <a href="https://www.di.ens.fr/willow/">Willow (Inria)</a>, supervised by <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a> and <a href="https://cshizhe.github.io/">Shizhe Chen</a>.
              </p>
              <p>
                My research interests lie primarily in 3D computer vision and robotics. Before my PhD, I graduated with distinction from the <a href="https://www.master-mva.com/">MVA</a> master program at <a href="https://ens-paris-saclay.fr/">ENS Paris Saclay</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:shiyao.li@enpc.fr">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/">Scholar</a> &nbsp/&nbsp
                <a href="https://x.com/LI_Shiyao16">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/shiyao-li">Github</a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shiyao-li-249549209/">Linkedln</a>
              </p>
            </td>
            <td style="padding: 10% 2% 10% 2%;width:40%;max-width:40%">
              <img src="assets/shiyao.jpg" width="220" alt="photo">
            </td>
          </tr>

        </tbody></table>

        <!-- Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-top:5px;padding-bottom:5px;padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- MVSplat360 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <video autoplay muted loop width="180">
                <source src="assets/exploration_nbp.mp4"
                        type="video/mp4">
              </video>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=7WaRh4gCXp">
                <papertitle>NextBestPath: Efficient 3D Mapping of Unseen Environments
                </papertitle>
              </a>
              <br>
              <strong>Shiyao Li</strong>,
              <a href="https://anttwo.github.io/">Antoine Guédon</a>,
              <a href="https://clementinboittiaux.github.io/">Clémentin Boittiaux</a>,
              <a href="https://cshizhe.github.io/">Shizhe Chen</a>,
              <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>
              <br>
              <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
              <br>
              <a href="https://shiyao-li.github.io/nbp1">project page</a>
              <!-- /
              <a href="">code</a>  -->
              <p>
                A method for generating the next-best-path for efficient active mapping, along with a new benchmark tailored for complex indoor environments.
              </p>
            </td>
          </tr>


        <!-- Invited Talks -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding-top:5px;padding-bottom:5px;padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
            <heading>Invited Talks</heading>
            <ul>
              <li>DepthSplat: Connecting Gaussian Splatting and Depth, <em>Google DeepMind</em>, hosted by <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>, 2024.10.29</li>
              <li>Unifying Flow, Stereo and Depth Estimation <a href="./slides/20221228_synced_unimatch.pdf">[slides]</a>,
                <em>Synced</em>, 2022.12.28</li>
              <li>GMFlow: Learning Optical Flow via Global Matching <a href="./slides/20220413_monash_gmflow.pdf">[slides]</a>, <em>Monash University</em>, 2022.04.13</li>
            </ul>
          </td>
          </tr>
        </tbody></table> -->


        <!-- Academic Services -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding-top:5px;padding-bottom:5px;padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <ul>
              <li>Conference Reviewer: ICCV 2021, CVPR 2022, ECCV 2022, CVPR 2023, NeurIPS 2023, CVPR 2024, ECCV 2024, NeurIPS 2024</li>
              <li>Journal Reviewer: TIP, IJCV, TPAMI</li>
            </ul>
          </td>
          </tr>
        </tbody></table>
 -->

        <!-- Awards and Honors -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding-top:5px;padding-bottom:5px;padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
            <ul>
              <li><a href="https://neurips.cc/Conferences/2024/ProgramCommittee#top-reviewers">Top Reviewer</a>, NeurIPS 2024</li>
              <li><a href="https://cvpr2022.thecvf.com/outstanding-reviewers">Outstanding Reviewer</a>, CVPR 2022</li>
              <li><a href="https://eval.ai/web/challenges/challenge-page/1704/leaderboard/4066">1<sup>st</sup> place of Argoverse Stereo Challenge</a>, <a href="http://cvpr2022.wad.vision/"> CVPR 2022 Workshop on Autonomous Driving</a></li>
              <li>National Scholarship, 2016</li>
            </ul>
          </td>
          </tr>
        </tbody></table> -->


        <!-- footnote -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="center">
              <font size="2">
              <a href="https://jonbarron.info/"><font size="2" color="lightgray">awesome website template</font></a>
              <br>
            </font>
            </p>
            </td>
          </tr>
          </table>

      </td>
    </tr>
  </table>

  




</body>

</html>
